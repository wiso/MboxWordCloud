{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a lot of modules. Many of them are not really needed, but why to reinvent the wheel? All of them can be installed with `pip install` or `python-pip install`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox                                      # to read mbox (and others) format\n",
    "from email_reply_parser import EmailReplyParser     # to split reply for the main message, see https://github.com/zapier/email-reply-parser\n",
    "from collections import Counter                     # to accumulate, probably there are better solution based on real histograms\n",
    "import email\n",
    "from string import maketrans\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import re\n",
    "from math import log, exp, sqrt\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer   # to parse text, it can do much more\n",
    "import pandas as pd                                           # to make tables\n",
    "#pd.core.format.set_option('notebook_repr_html', True)     # in HTML\n",
    "from IPython.display import display_pretty, display_html, display_jpeg, display_png, display_json, display_latex, display_svg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = STOPWORDS.copy()\n",
    "mystopwords = '21 03 11 16 30 17 b9 05 14 04 13 19 06 12 a9 07 08 25 09 18 pj4 c3 a0 a3 ac 10 b2 della type 01 02 just 20 00 02c3 a8 utf alla del po 40miinfnit 2eit 40mi tra alle 3e 3a 2c questo ve al f2 gli su cosa quello nel pi ti sia e2 anche ec lo don anche com http https e1 ch sono ma ci se e8 e0 ruggero turra saluti cheers da salve una un le ho ciao hello hi non di che la plain text ha new mi 24 content il 2014 jan wed charset all six less being indeed over move anyway four not own through yourselves fify where mill only find before one whose system how somewhere with thick show had enough should to must whom seeming under ours has might thereafter latterly do them his around than get very de none cannot every whether they front during thus now him nor name several hereafter always who cry whither this someone either each become thereupon sometime side two therein twelve because often ten our eg some back up go namely towards are further beyond ourselves yet out even will what still for bottom mine since please forty per its everything behind un above between it neither seemed ever across she somehow be we full never sixty however here otherwise were whereupon nowhere although found alone re along fifteen by both about last would anything via many could thence put against keep etc amount became ltd hence onto or con among already co afterwards formerly within seems into others while whatever except down hers everyone done least another whoever moreover couldnt throughout anyhow yourself three from her few together top there due been next anyone eleven much call therefore interest then thru themselves hundred was sincere empty more himself elsewhere mostly on fire am becoming hereby amongst else part everywhere too herself former those he me myself made twenty these bill cant us until besides nevertheless below anywhere nine can of your toward my something and whereafter whenever give almost wherever is describe beforehand herein an as itself at have in seem whence ie any fill again hasnt inc thereby thin no perhaps latter meanwhile when detail same wherein beside also that other take which becomes you if nobody see though may after upon most hereupon eight but serious nothing such why a off whereby third i whole noone sometimes well amoungst yours their rather without so five the first whereas once'\n",
    "for m in mystopwords.split():\n",
    "    stopwords.add(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to download the whole gmail emails, it can be done here: https://www.google.com/settings/takeout. By the way this code works with any `mbox` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_identities = [x.encode('rot13') for x in 'ehttreb.gheen@zv.vasa.vg', 'tvheereb@tznvy.pbz', 'ehttreb.gheen@prea.pu', 'e.gheen@prea.pu', 'egheen@prea.pu', 'Ehttreb Gheen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very slow\n",
    "mbox = mailbox.mbox('/home/turra/Posta inviata.mbox')\n",
    "len(mbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_after = 0 # number of email to read. Set to 0 if you want to read all the emails\n",
    "year = 2017      # year to read, skip the others. Set to 0 if you want to read all the years\n",
    "box_name = \"Posta inviata\"\n",
    "\n",
    "recipients_name = Counter()\n",
    "recipients_email = Counter()\n",
    "sent_hour = Counter(dict(zip(range(24), [0] * 24)))\n",
    "sent_day = Counter(dict(zip(range(1, 7), [0] * 7)))\n",
    "sent_month = Counter(dict(zip(range(1, 12), [0] * 11)))\n",
    "len_replies = Counter()\n",
    "words_count = Counter()\n",
    "\n",
    "trantab = maketrans('\\t\\r\\n', '   ')\n",
    "r1 = re.compile(r'Il (giorno )?[0-9].*?@.*?scritto=?:', re.MULTILINE|re.DOTALL)\n",
    "r7 = re.compile(r'On [0-9].*?@.*?wrote=?:', re.MULTILINE|re.DOTALL)\n",
    "r2 = re.compile(r'From nobody.*?\\n', re.DOTALL)\n",
    "r3 = re.compile('Content-Type.*?$')\n",
    "r4 = re.compile(r'[0-9].*?\\@.*?:')\n",
    "r5 = re.compile(r'\\=[0-9]+[A-Z]')\n",
    "r6 = re.compile(r' [0-9]+ ')\n",
    "\n",
    "to_remove = ('Content-Disposition: inline',\n",
    "             'Content-Type: text/plain; charset=ISO-8859-1',\n",
    "             'Content-Type: text/plain; charset=windows-1252',\n",
    "             'Content-Transfer-Encoding: quoted-printable',\n",
    "             '.cern.ch')\n",
    "cv = CountVectorizer(min_df=0, stop_words=stopwords, max_features=500)\n",
    "\n",
    "for i, message in enumerate(tqdm(mbox)):\n",
    "    try:\n",
    "        if not message.has_key('X-Gmail-Labels'):\n",
    "            continue\n",
    "        if \"Chat\" in message['X-Gmail-Labels']:\n",
    "            continue\n",
    "        if box_name in message['X-Gmail-Labels']:\n",
    "            To = message['To']       \n",
    "            From = message['From']\n",
    "            if not From:\n",
    "                continue\n",
    "            if not any(my_id in From for my_id in my_identities):\n",
    "                continue\n",
    "            date = datetime(*(email.utils.parsedate(message['date'])[:7]))\n",
    "            if year and date.year != year:\n",
    "                continue\n",
    "            sent_hour.update({date.hour: 1})\n",
    "            sent_day.update({date.isoweekday(): 1})\n",
    "            sent_month.update({date.month: 1})\n",
    "\n",
    "            if To:\n",
    "                tos = [x.translate(trantab).strip() for x in To.split(',')]       \n",
    "                to_parsed = email.utils.getaddresses(tos)\n",
    "                for to in to_parsed:\n",
    "                    recipients_name.update({to[0].lower(): 1})\n",
    "                    recipients_email.update({to[1].lower(): 1})\n",
    "\n",
    "            if message.is_multipart():           \n",
    "                payload = str(message.get_payload()[0])\n",
    "            else:\n",
    "                payload = message.get_payload()\n",
    "\n",
    "            erp = EmailReplyParser.read(payload)\n",
    "            fragments = erp.fragments\n",
    "            len_replies.update({len(fragments): 1})\n",
    "            my_message = fragments[0].content\n",
    "\n",
    "            my_message = reduce(lambda x, y: x.replace(y, ' '), to_remove, my_message)\n",
    "            my_message = reduce(lambda y, x: x.sub('', y), (r1, r2, r3, r4, r5, r6, r7), my_message)\n",
    "            my_message = my_message.strip()               \n",
    "\n",
    "            if len(my_message):\n",
    "                try:\n",
    "                    counts = cv.fit_transform([my_message]).toarray().ravel()\n",
    "                    words = np.array(cv.get_feature_names())\n",
    "                    words_count.update(dict(zip(words, counts)))\n",
    "                except:\n",
    "                    logging.error('Cannot parse: \"%s\"', my_message)\n",
    "            #print my_message\n",
    "    except:\n",
    "        print \"problem with message\"\n",
    "        print message\n",
    "        raise\n",
    "    if stop_after and i > stop_after:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_hour = pd.DataFrame.from_dict(sent_hour, orient=\"index\")\n",
    "sent_hour.columns = ['#emails']\n",
    "sent_day = pd.DataFrame.from_dict(sent_day, orient=\"index\")\n",
    "sent_day.columns = ['#emails']\n",
    "sent_month = pd.DataFrame.from_dict(sent_month, orient=\"index\")\n",
    "sent_month.columns = ['#emails']\n",
    "len_replies = pd.DataFrame.from_dict(len_replies, orient=\"index\")\n",
    "len_replies.columns = ['#emails']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_hour.plot(kind='bar', figsize=(14, 6))\n",
    "sent_day.plot(kind='bar', figsize=(14, 6))\n",
    "sent_month.plot(kind='bar', figsize=(14, 6))\n",
    "len_replies.plot(figsize=(14, 6), xlim=(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in words_count.most_common(300):\n",
    "    if x in stopwords:\n",
    "        continue\n",
    "    print \"%s: %d\" % (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "import random\n",
    "\n",
    "def grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    return \"hsl(20, 80%%, %d%%)\" % random.randint(30, 90)\n",
    "\n",
    "mask = imread(\"/home/turra/bitmap.png\")\n",
    "#col = imread(\"/home/turra/2016_col.png\")\n",
    "#image_colors = ImageColorGenerator(col)\n",
    "\n",
    "freq = [(a, (float(b) / words_count.most_common(1)[0][1]) **2) for a, b in words_count.most_common(700) if a not in stopwords]\n",
    "wordcloud = WordCloud(width=800, height=1080, max_words=700, scale=2,\n",
    "                      background_color=\"black\",\n",
    "                      mask=mask,\n",
    "                      stopwords=stopwords).generate_from_frequencies(dict(freq))\n",
    "wordcloud.recolor(color_func=grey_color_func, random_state=3)\n",
    "#wordcloud.recolor(color_func=image_colors)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud.to_file('temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
